# Default Application Properties for Spark Job Module
# This file provides property-based configuration as fallback for application.yml

# Spring Configuration
spring.application.name=spark-transform-job
spring.main.allow-bean-definition-overriding=true
spring.main.lazy-initialization=false
spring.autoconfigure=true

# Database Configuration
spring.datasource.driver-class-name=org.postgresql.Driver
spring.datasource.url=jdbc:postgresql://localhost:5432/spark_transform
spring.datasource.username=spark_user
spring.datasource.password=spark_password
spring.datasource.hikari.maximum-pool-size=10
spring.datasource.hikari.minimum-idle=5
spring.datasource.hikari.connection-timeout=30000

# Redis Configuration
spring.redis.host=localhost
spring.redis.port=6379
spring.redis.timeout=2000ms
spring.redis.database=0

# Custom Partition Configuration
custom.partition.enabled=true
custom.partition.environment=spark-partition
custom.partition.connection-pool-size=10
custom.partition.timeout-ms=30000
custom.partition.advanced.enabled=false

# Logging Configuration
logging.level.com.ssc.isvc=INFO
logging.level.com.sparktransform=INFO
logging.level.org.springframework=WARN
logging.level.root=INFO

# Configuration Exclusions
exclusions.configurations=com.some.library.UnwantedConfiguration,com.another.library.ProblematicConfig
exclusions.packages=com.problematic.library,com.unwanted.package
exclusions.patterns=SecurityConfig,WebConfig,ServletConfig
